---
title: "Predicting Compromised Security with VCDB"
author: "John Sullivan, Enrique Preciado, Eddie Yantis"
date: "May 14, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

The data set came in a huge CSV file (https://github.com/vz-risk/VCDB/blob/master/data/csv/vcdb.csv) that was not very R-friendly, with thousands of hyper-specific columns that were nothing but True/False values. For example, instead of a single "Environmental" column that held values such as "Hurricane," "Volcano" or "EMP" there was a separate column for each. These two functions collapsed these columns into one.

```{r functions}

library(e1071)

source("lin-regr-util.R")

transform_row = function(dat, name)
{
  subframe = dat[,grep(name, colnames(dat))]
  sub = apply(subframe, 1, function(x) return(ifelse( is.numeric(which(x == TRUE)), substring(colnames(subframe)[which(x == TRUE)], nchar(name) + 1), NA)))
  return(sub)
}

transform_dot = function(dat, name)
{
  subframe = dat[,grep(name, colnames(dat))]
  sub = apply(subframe, 1, function(x) return(substring(colnames(subframe)[which(x == TRUE)], regexpr("\\.[^\\.]*$", colnames(subframe)[which(x == TRUE)]) + 1)))
  return(sub)
}

```

## Data readin and cleanup

Now we read in the dataset. The original data contains 2,041 columns. Most of these are incomplete or not useful and right off the bat we can eliminate about 1,500 of them. 


```{r cleanup}

dat = read.csv("vcdb.csv")

dat = dat[,names(dat) != "X"]
dat = dat[,-grep("action.environmental", colnames(dat))]
dat = dat[,-grep("action.error", colnames(dat))]
dat = dat[,-grep("action.hacking", colnames(dat))]
dat = dat[,-grep("action.malware", colnames(dat))]
dat = dat[,-grep("action.misuse", colnames(dat))]
dat = dat[,-grep("action.physical", colnames(dat))]
dat = dat[,-grep("action.social", colnames(dat))]
dat = dat[,-grep("action.unknown", colnames(dat))]
dat = dat[,-grep("actor", colnames(dat))]
dat = dat[,-grep("campaign", colnames(dat))]
dat = dat[,-grep("confidence", colnames(dat))]
dat = dat[,-grep("control", colnames(dat))]
dat = dat[,-grep("corrective", colnames(dat))]
dat = dat[,-grep("cost", colnames(dat))]
dat = dat[,-grep("impact", colnames(dat))]
dat = dat[,-grep("plus", colnames(dat))]
dat = dat[,-grep("targeted", colnames(dat))]
dat = dat[,-grep("timeline.compromise", colnames(dat))]
dat = dat[,-grep("timeline.exfiltration", colnames(dat))]
dat = dat[,-grep("timeline.containment", colnames(dat))]
dat = dat[,-grep("security_incident", colnames(dat))]
dat = dat[,-grep("victim.revenue.iso_currency_code", colnames(dat))]
dat = dat[,-grep("victim.industry2", colnames(dat))]
dat = dat[,-grep("victim.industry3", colnames(dat))]
dat = dat[,-grep("pattern.", colnames(dat))]
dat = dat[,-grep("incident_id", colnames(dat))]
dat = dat[,-grep("notes", colnames(dat))]
dat = dat[,-grep("reference", colnames(dat))]
dat = dat[,-grep("schema_version", colnames(dat))]
dat = dat[,-grep("source_id", colnames(dat))]
dat = dat[,-grep("timeline.incident.day", colnames(dat))]
dat = dat[,-grep("timeline.incident.time", colnames(dat))]
dat = dat[,-grep("victim.locations_affected", colnames(dat))]
dat = dat[,-grep("victim.secondary", colnames(dat))]
dat = dat[,-grep("victim.region", colnames(dat))]
dat = dat[,-grep("victim.orgsize.", colnames(dat))]
dat = dat[,-grep("victim.revenue.amount", colnames(dat))]

```


There is some useful data here, so we're going to transform it into a usable form. We're limiting ourselves to attacks in the United States. We're alse going to save the number of employees in the organization (In the original dataset, this is given as a range of 1 to 10, 10 to 100, etc. We're saving only the upper limit; 1 to 10 is saved as "10" and so on.)

"Action" saves a brief description of the type of attack. It may be a user error, an actual attack, an accident, etc. "Target" is a brief description of what was taken. "Disclosed" is whether the confidential data was leaked, data_status is whether the data was encrypted or not. "Victim" is who was affected. Finally, we remove the columns we transformed. Month and year are self-explanitory. The last thing we do is remove rows where the month is NA and throw out all attacks before 2007. This final cleanup and transformation reduces the set to 15 features.


```{r cleanup 2: electric boogaloo}

dat$victim.country = transform_row(dat, "victim.country.")
dat = dat[,-grep("victim.country.", colnames(dat))]

dat = dat[dat$victim.country == "US",]
dat = dat[,-grep("victim.country", colnames(dat))]

dat$victim.employee_count = transform_dot(dat, "victim.employee_count.")
dat = dat[,-grep("victim.employee_count.", colnames(dat))]

dat$action = transform_row(dat,"action.")
dat = dat[,-grep("action.", colnames(dat))]

dat$target = transform_row(dat,"attribute.confidentiality.data.variety.")
dat$disclosed = transform_row(dat,"attribute.confidentiality.data_disclosure.")
dat$records = dat$attribute.confidentiality.data_total
dat$data_status = transform_row(dat,"attribute.confidentiality.state.")
dat$victim = dat$attribute.confidentiality.data_victim

dat = dat[,-grep("asset.", colnames(dat))]
dat = dat[,-grep("attribute.", colnames(dat))]
dat = dat[,-grep("discovery.", colnames(dat))]

dat = dat[!is.na(dat$timeline.incident.month),]
dat = dat[as.numeric(dat$timeline.incident.year) >= 2007,]

names(dat)=c("summary","month","year","industry","state","name","type","pattern","employees","action","target","disclosed","records","data_status","victim")

dat$month = factor(dat$month)
dat$year = factor(dat$year)
dat$employees = factor(dat$employees)
dat$industry = factor(dat$industry)
dat$records = factor(dat$records)
dat$type = factor(dat$type)

par(mar = c(4.1, 8.1, 4.1, 4.1))
barplot(sort(table(dat$type)), las=2, main = "Incidents per Industry", horiz = TRUE, col = "firebrick")

barplot(sort(table(dat$action)), las=2, main = "Incident category", horiz = TRUE, col = "firebrick")

barplot(sort(table(dat$victim))[12:18],las=2, main = "Victims of the incidents", horiz = TRUE, col = "firebrick")

par(mar = c(4.1, 9.1, 2.1, 1))
barplot(sort(table(dat$pattern)), las=2, main = "Types of attacks", horiz = TRUE, col = "firebrick")
barplot(sort(table(dat$data_status)), las=2, main="Data status upon theft", horiz = TRUE, col = "firebrick")

```



Now we build the model. We use Naive Bayes to predict the Industry type based on attack features. Unfortunately even after many, many hours of data munging, massaging and feature testing, our best prediction scored an unimpressive 62%. 

```{r naive bayes is naive, message = FALSE}
barplot(table(dat$month,dat$year), main = "Incidents over time")

set.seed(123)
splits = split_data(dat,c(.8,.2))
tr_dat = splits[[1]]
te_dat = splits[[2]]

fit = naiveBayes(type ~ victim+employees, data=tr_dat)

predicted = predict(fit, newdata = te_dat)
actuals = te_dat$type

mean(predicted==actuals)

table(predicted, actuals)
```